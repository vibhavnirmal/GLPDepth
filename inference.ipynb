{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.logging as logging\n",
    "import utils.metrics as metrics\n",
    "\n",
    "from models.model import GLPDepth\n",
    "from dataset.base_dataset import get_dataset\n",
    "from configs.test_options import TestOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = ['d1', 'd2', 'd3', 'abs_rel', 'sq_rel', 'rmse', 'rmse_log', 'log10', 'silog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments setting\n",
    "opt = TestOptions()\n",
    "args = opt.initialize().parse_args()\n",
    "print(args)\n",
    "\n",
    "if args.gpu_or_cpu == 'gpu':\n",
    "    device = torch.device('cuda')\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "if args.save_eval_pngs or args.save_visualize:\n",
    "    result_path = os.path.join(args.result_dir, args.exp_name)\n",
    "    logging.check_and_make_dirs(result_path)\n",
    "    print(\"Saving result images in to %s\" % result_path)\n",
    "\n",
    "if args.do_evaluate:\n",
    "    result_metrics = {}\n",
    "    for metric in metric_name:\n",
    "        result_metrics[metric] = 0.0\n",
    "\n",
    "print(\"\\n1. Define Model\")\n",
    "model = GLPDepth(max_depth=args.max_depth, is_train=False).to(device)\n",
    "model_weight = torch.load(args.ckpt_dir)\n",
    "if 'module' in next(iter(model_weight.items()))[0]:\n",
    "    model_weight = OrderedDict((k[7:], v) for k, v in model_weight.items())\n",
    "model.load_state_dict(model_weight)\n",
    "model.eval()\n",
    "\n",
    "print(\"\\n2. Define Dataloader\")\n",
    "if args.dataset == 'imagepath': # not for do_evaluate in case of imagepath\n",
    "    dataset_kwargs = {'dataset_name': 'ImagePath', 'data_path': args.data_path}\n",
    "else:\n",
    "    dataset_kwargs = {'data_path': args.data_path, 'dataset_name': args.dataset,\n",
    "                    'is_train': False}\n",
    "\n",
    "test_dataset = get_dataset(**dataset_kwargs)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False,\n",
    "                        pin_memory=True)\n",
    "\n",
    "print(\"\\n3. Inference & Evaluate\")\n",
    "for batch_idx, batch in enumerate(test_loader):\n",
    "    input_RGB = batch['image'].to(device)\n",
    "    filename = batch['filename']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(input_RGB)\n",
    "    pred_d = pred['pred_d']\n",
    "\n",
    "    if args.do_evaluate:\n",
    "        depth_gt = batch['depth'].to(device)\n",
    "        pred_d, depth_gt = pred_d.squeeze(), depth_gt.squeeze()\n",
    "        pred_crop, gt_crop = metrics.cropping_img(args, pred_d, depth_gt)\n",
    "        computed_result = metrics.eval_depth(pred_crop, gt_crop)\n",
    "        for metric in metric_name:\n",
    "            result_metrics[metric] += computed_result[metric]\n",
    "\n",
    "    if args.save_eval_pngs:\n",
    "        save_path = os.path.join(result_path, filename[0])\n",
    "        if save_path.split('.')[-1] == 'jpg':\n",
    "            save_path = save_path.replace('jpg', 'png')\n",
    "        pred_d = pred_d.squeeze()\n",
    "        if args.dataset == 'nyudepthv2':\n",
    "            pred_d = pred_d.cpu().numpy() * 1000.0\n",
    "            cv2.imwrite(save_path, pred_d.astype(np.uint16),\n",
    "                        [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "        else:\n",
    "            pred_d = pred_d.cpu().numpy() * 256.0\n",
    "            cv2.imwrite(save_path, pred_d.astype(np.uint16),\n",
    "                        [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "        \n",
    "    if args.save_visualize:\n",
    "        save_path = os.path.join(result_path, filename[0])\n",
    "        pred_d_numpy = pred_d.squeeze().cpu().numpy()\n",
    "        pred_d_numpy = (pred_d_numpy / pred_d_numpy.max()) * 255\n",
    "        pred_d_numpy = pred_d_numpy.astype(np.uint8)\n",
    "        pred_d_color = cv2.applyColorMap(pred_d_numpy, cv2.COLORMAP_RAINBOW)\n",
    "        cv2.imwrite(save_path, pred_d_color)\n",
    "    logging.progress_bar(batch_idx, len(test_loader), 1, 1)\n",
    "\n",
    "if args.do_evaluate:\n",
    "    for key in result_metrics.keys():\n",
    "        result_metrics[key] = result_metrics[key] / (batch_idx + 1)\n",
    "    display_result = logging.display_result(result_metrics)\n",
    "    if args.kitti_crop:\n",
    "        print(\"\\nCrop Method: \", args.kitti_crop)\n",
    "    print(display_result)\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
